{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpAUh2JPFxtu"
      },
      "source": [
        "# BERTBQ: Taglish Complaint Classification for Philippine E-Commerce Reviews\n",
        "## Using Multilingual Transformers (XLM-RoBERTa & RoBERTa-TL)\n",
        "\n",
        "This notebook implements a complaint classification system for Taglish (Tagalog-English) reviews from Philippine e-commerce platforms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8wxer7KFxtw"
      },
      "source": [
        "## 1. Setup and Installation\n",
        "Run this cell first to install all required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y3mikZlLFxtw"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers datasets accelerate scikit-learn pandas numpy matplotlib seaborn wordcloud emoji optuna\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ1pMXmmeOaG"
      },
      "source": [
        "\n",
        "\n",
        "Installs all the necessary libraries for the project. The first command installs libraries used for natural language processing, data processing, and visualization, including Transformers, Datasets, Accelerate, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, WordCloud, and Emoji. The second command installs PyTorch along with Torchvision and Torchaudio, using a CUDA-compatible version to enable GPU acceleration if available.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAYw2dexFxtx"
      },
      "source": [
        "## 2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QSejENbFxtx",
        "outputId": "5c53288e-01b1-46a2-fa3f-8904ef23261b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import re\n",
        "import emoji\n",
        "from collections import Counter\n",
        "\n",
        "# Hugging Face imports\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# Sklearn imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ptWRsbgMqR"
      },
      "source": [
        "\n",
        "\n",
        "Imports all the required Python libraries for data processing, visualization, natural language processing, and machine learning. Warnings are disabled for cleaner output. Core libraries such as NumPy, Pandas, and PyTorch are loaded for numerical computation, data handling, and model training. Visualization tools such as Matplotlib and Seaborn are imported for creating plots. Additional utilities such as regular expressions, emoji handling, and word frequency counting are included.\n",
        "\n",
        "Hugging Face libraries are imported to handle tokenization, dataset loading, and model training. Scikit-learn modules are imported for data splitting, feature extraction, machine learning modeling, and evaluation.\n",
        "\n",
        "A fixed random seed is set to ensure reproducibility of results. The code checks whether a GPU is available and prints the device being used for computation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga6yUr0nFxty"
      },
      "source": [
        "## 3. Load and Explore the Dataset\n",
        "We'll use the SentiTaglishProductsAndServices dataset from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duDHskRpFxty",
        "outputId": "dd83091e-36e3-4688-9418-304f12bf64d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "Available splits: ['train']\n",
            "\n",
            "Number of training samples: 10510\n",
            "Features: {'review': Value('string'), 'sentiment': Value('int64')}\n",
            "\n",
            "Sample entry:\n",
            "{'review': 'at first gumagana cya..pero pagnalowbat cya ndi na ya magamit kahit ilang oras mo cya icharge namamatay agad..poor quality..not for recommended..', 'sentiment': 1}\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    dataset = load_dataset(\"ccosme/SentiTaglishProductsAndServices\")\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(f\"Available splits: {list(dataset.keys())}\")\n",
        "\n",
        "    # Display dataset info\n",
        "    if 'train' in dataset:\n",
        "        print(f\"\\nNumber of training samples: {len(dataset['train'])}\")\n",
        "        print(f\"Features: {dataset['train'].features}\")\n",
        "\n",
        "        # Show sample\n",
        "        print(\"\\nSample entry:\")\n",
        "        print(dataset['train'][0])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not load dataset: {e}\")\n",
        "    print(\"Creating sample dataset for demonstration...\")\n",
        "\n",
        "    # Create sample Taglish dataset\n",
        "    sample_data = {\n",
        "        'text': [\n",
        "            \"Sobrang bagal ng delivery, 2 weeks bago dumating!\",\n",
        "            \"The product is good pero mahal masyado for the quality\",\n",
        "            \"Ang ganda ng packaging at mabilis ang shipping\",\n",
        "            \"Sira yung item na natanggap ko, requesting refund\",\n",
        "            \"Great seller, very responsive and helpful!\",\n",
        "            \"Hindi tugma sa description, disappointed ako\",\n",
        "            \"Worth it! Sulit na sulit ang price\",\n",
        "            \"Late delivery tapos wrong item pa ang natanggap\",\n",
        "            \"Excellent quality, exactly as described\",\n",
        "            \"Ang pangit ng customer service, di nagrereply\",\n",
        "            \"Super satisfied with my purchase!\",\n",
        "            \"Defective yung product, waste of money\",\n",
        "            \"Fast shipping and good packaging\",\n",
        "            \"Scam ba ito? Hindi tugma sa picture\",\n",
        "            \"Highly recommended seller!\"\n",
        "        ] * 20,  # Multiply for more samples\n",
        "        'label': [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0] * 20\n",
        "    }\n",
        "\n",
        "    dataset = DatasetDict({'train': Dataset.from_dict(sample_data)})\n",
        "    print(f\"Sample dataset created with {len(dataset['train'])} entries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XCIaHiKgvlu"
      },
      "source": [
        "This section attempts to load a Taglish sentiment dataset from Hugging Face. If the dataset is successfully loaded, the code prints its available splits, the number of training samples, the feature information, and displays a sample entry. If the dataset cannot be loaded due to an error, a fallback sample dataset is created manually for demonstration purposes. The sample dataset contains Taglish product and service reviews with corresponding sentiment labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJMBtn0lFxty"
      },
      "source": [
        "## 4. Data Preprocessing\n",
        "Clean and prepare the Taglish text for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDIpKS7xQMIh",
        "outputId": "c6c06e5e-0f01-40b5-daf2-093a28dbf1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10510 samples\n",
            "\n",
            "Label Distribution:\n",
            "  Complaints (1): 6805 (64.7%)\n",
            "  Non-complaints (0): 3705 (35.3%)\n"
          ]
        }
      ],
      "source": [
        "def clean_taglish_text(text):\n",
        "    \"\"\"Clean and normalize Taglish text\"\"\"\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return \"\"\n",
        "\n",
        "    text = str(text)\n",
        "\n",
        "    # Handle emojis\n",
        "    text = emoji.demojize(text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "\n",
        "    # Handle repeated characters\n",
        "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
        "\n",
        "    # Handle excessive punctuation\n",
        "    text = re.sub(r'[!?]{2,}', '!', text)\n",
        "    text = re.sub(r'\\.{2,}', '.', text)\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# Process the dataset\n",
        "def preprocess_dataset(dataset):\n",
        "    \"\"\"Preprocess the entire dataset\"\"\"\n",
        "    processed_data = []\n",
        "\n",
        "    for item in dataset:\n",
        "        # Find text field\n",
        "        text = None\n",
        "        for field in ['text', 'review', 'review_text', 'content']:\n",
        "            if field in item:\n",
        "                text = item[field]\n",
        "                break\n",
        "\n",
        "        # Find label field\n",
        "        label = None\n",
        "        for field in ['label', 'sentiment', 'sentiment_label']:\n",
        "            if field in item:\n",
        "                label = item[field]\n",
        "                break\n",
        "\n",
        "        if text and label is not None:\n",
        "            cleaned_text = clean_taglish_text(text)\n",
        "\n",
        "            # Convert sentiment labels (1–4) to binary complaint labels\n",
        "            # 1 = Negative → Complaint (1)\n",
        "            # 2 = Neutral  → Non-Complaint (0)\n",
        "            # 3 = Positive → Non-Complaint (0)\n",
        "            # 4 = Mixed    → Complaint (1)\n",
        "            try:\n",
        "                label = int(label)\n",
        "                if label in [1, 4]:\n",
        "                    binary_label = 1\n",
        "                elif label in [2, 3]:\n",
        "                    binary_label = 0\n",
        "                else:\n",
        "                    binary_label = 0\n",
        "            except:\n",
        "                # If labels are strings like 'positive', 'negative'\n",
        "                binary_label = 1 if str(label).lower() in ['negative', 'mixed'] else 0\n",
        "\n",
        "            processed_data.append({\n",
        "                'text': cleaned_text,\n",
        "                'label': binary_label\n",
        "            })\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "# Process the data\n",
        "if 'train' in dataset:\n",
        "    processed_data = preprocess_dataset(dataset['train'])\n",
        "else:\n",
        "    processed_data = preprocess_dataset(dataset)\n",
        "\n",
        "print(f\"Processed {len(processed_data)} samples\")\n",
        "\n",
        "# Check label distribution\n",
        "labels = [item['label'] for item in processed_data]\n",
        "print(f\"\\nLabel Distribution:\")\n",
        "print(f\"  Complaints (1): {sum(labels)} ({sum(labels)/len(labels)*100:.1f}%)\")\n",
        "print(f\"  Non-complaints (0): {len(labels)-sum(labels)} ({(len(labels)-sum(labels))/len(labels)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaULOAF9h2Bn"
      },
      "source": [
        "This functions used to clean and normalize Taglish text before modeling. The `clean_taglish_text` function handles emoji conversion, removes URLs, reduces repeated characters, normalizes punctuation, and trims extra spaces to produce cleaner input text. The `preprocess_dataset` function applies this cleaning process to the entire dataset while also converting original sentiment labels into binary labels, where values indicating negative or mixed sentiment are treated as complaints (1), and positive or neutral sentiments are treated as non-complaints (0). After preprocessing, the code prints the number of processed samples and displays the distribution of complaint versus non-complaint labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfvHch22Fxtz"
      },
      "source": [
        "## 5. Split the Dataset\n",
        "Create train, validation, and test sets with stratification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2VuA6_yFxtz",
        "outputId": "c04945ce-5f22-45cb-9198-ee13d34738d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits:\n",
            "  Train: 7360 samples\n",
            "  Validation: 1573 samples\n",
            "  Test: 1577 samples\n",
            "  Train complaint ratio: 64.76%\n",
            "  Val complaint ratio: 64.72%\n",
            "  Test complaint ratio: 64.74%\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(processed_data)\n",
        "\n",
        "# Split data: 70% train, 15% validation, 15% test\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df, test_size=0.15, stratify=df['label'], random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df, test_size=0.176, stratify=train_val_df['label'], random_state=RANDOM_SEED\n",
        ")  # 0.176 ≈ 15% of original\n",
        "\n",
        "print(f\"Dataset splits:\")\n",
        "print(f\"  Train: {len(train_df)} samples\")\n",
        "print(f\"  Validation: {len(val_df)} samples\")\n",
        "print(f\"  Test: {len(test_df)} samples\")\n",
        "\n",
        "# Verify stratification\n",
        "for name, split_df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
        "    complaint_ratio = split_df['label'].mean()\n",
        "    print(f\"  {name} complaint ratio: {complaint_ratio:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucvZ8t2riT_j"
      },
      "source": [
        "Converting to DataFrame and Splitting the Data\n",
        "\n",
        "Converts the processed data into a Pandas DataFrame for easier manipulation. The dataset is then split into training, validation, and test sets, where 70% is used for training, 15% for validation, and 15% for testing. Stratified sampling is applied to ensure that the proportion of complaint and non-complaint labels remains consistent across all splits. After splitting, the code prints the number of samples in each group and verifies that the label distribution is balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmszP1J8Fxtz"
      },
      "source": [
        "## 6. Baseline Model: TF-IDF + Logistic Regression\n",
        "Establish baseline performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0-OE0MSFxtz",
        "outputId": "2221285c-c0d3-4a67-9dbc-51fb0143206a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Baseline Model (TF-IDF + Logistic Regression)\n",
            "==================================================\n",
            "TF-IDF features shape: (7360, 5000)\n",
            "\n",
            "Baseline Validation Results:\n",
            "  Accuracy: 0.8970\n",
            "  Precision: 0.8898\n",
            "  Recall: 0.8831\n",
            "  F1-Score: 0.8863\n",
            "\n",
            "Baseline Test Results:\n",
            "  accuracy: 0.8935\n",
            "  precision: 0.8833\n",
            "  recall: 0.8833\n",
            "  f1: 0.8833\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Baseline Model (TF-IDF + Logistic Regression)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3),\n",
        "    min_df=2,\n",
        "    max_df=0.95\n",
        ")\n",
        "\n",
        "# Vectorize text\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
        "X_val_tfidf = tfidf_vectorizer.transform(val_df['text'])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['text'])\n",
        "\n",
        "print(f\"TF-IDF features shape: {X_train_tfidf.shape}\")\n",
        "\n",
        "# Train Logistic Regression\n",
        "lr_classifier = LogisticRegression(\n",
        "    random_state=RANDOM_SEED,\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "lr_classifier.fit(X_train_tfidf, train_df['label'])\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_pred_baseline = lr_classifier.predict(X_val_tfidf)\n",
        "val_acc = accuracy_score(val_df['label'], val_pred_baseline)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    val_df['label'], val_pred_baseline, average='macro'\n",
        ")\n",
        "\n",
        "print(f\"\\nBaseline Validation Results:\")\n",
        "print(f\"  Accuracy: {val_acc:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall: {recall:.4f}\")\n",
        "print(f\"  F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Test set evaluation\n",
        "test_pred_baseline = lr_classifier.predict(X_test_tfidf)\n",
        "baseline_test_metrics = {\n",
        "    'accuracy': accuracy_score(test_df['label'], test_pred_baseline),\n",
        "    'precision': precision_recall_fscore_support(test_df['label'], test_pred_baseline, average='macro')[0],\n",
        "    'recall': precision_recall_fscore_support(test_df['label'], test_pred_baseline, average='macro')[1],\n",
        "    'f1': precision_recall_fscore_support(test_df['label'], test_pred_baseline, average='macro')[2]\n",
        "}\n",
        "\n",
        "print(f\"\\nBaseline Test Results:\")\n",
        "for metric, value in baseline_test_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KWKjD4sinuo"
      },
      "source": [
        "Trains a baseline text classification model using TF-IDF features and Logistic Regression. The TF-IDF vectorizer converts the text into numerical features based on word frequency patterns, using unigrams, bigrams, and trigrams while limiting vocabulary size and removing very rare or overly common terms. These features are used to train a Logistic Regression classifier with balanced class weights to handle any label imbalance. The model is first evaluated on the validation set to check performance during development, and then tested on the test set to obtain final baseline accuracy, precision, recall, and F1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDLo2mrPFxt0"
      },
      "source": [
        "## 7. Feature Analysis for Baseline\n",
        "Identify important words for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVqN-SYlFxt0",
        "outputId": "6dcff2ce-e71a-44cd-bc0b-f121339a017f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 Complaint Indicators:\n",
            "  kaso: 6.852\n",
            "  not: 5.517\n",
            "  pero: 4.358\n",
            "  disappointed: 3.527\n",
            "  lang: 3.286\n",
            "  yung: 3.171\n",
            "  hindi: 3.079\n",
            "  but: 3.003\n",
            "  sira: 2.944\n",
            "  di: 2.842\n",
            "  sayang: 2.523\n",
            "  tapos: 2.352\n",
            "  mali: 2.321\n",
            "  wrong: 2.303\n",
            "  poor: 2.241\n",
            "\n",
            "Top 15 Non-Complaint Indicators:\n",
            "  ganda: -5.072\n",
            "  thank: -3.598\n",
            "  super: -3.215\n",
            "  salamat: -2.863\n",
            "  love: -2.759\n",
            "  maganda: -2.563\n",
            "  thank you: -2.531\n",
            "  good: -2.509\n",
            "  ulit: -2.454\n",
            "  nice: -2.444\n",
            "  sulit: -2.338\n",
            "  safe: -2.316\n",
            "  ang ganda: -2.296\n",
            "  thankyou: -2.156\n",
            "  thanks: -2.145\n"
          ]
        }
      ],
      "source": [
        "# Get feature importance\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "coef = lr_classifier.coef_[0]\n",
        "\n",
        "# Top complaint indicators\n",
        "top_complaint_idx = coef.argsort()[-15:][::-1]\n",
        "top_complaint_features = [(feature_names[i], coef[i]) for i in top_complaint_idx]\n",
        "\n",
        "print(\"Top 15 Complaint Indicators:\")\n",
        "for feature, score in top_complaint_features:\n",
        "    print(f\"  {feature}: {score:.3f}\")\n",
        "\n",
        "# Top non-complaint indicators\n",
        "top_non_complaint_idx = coef.argsort()[:15]\n",
        "top_non_complaint_features = [(feature_names[i], coef[i]) for i in top_non_complaint_idx]\n",
        "\n",
        "print(\"\\nTop 15 Non-Complaint Indicators:\")\n",
        "for feature, score in top_non_complaint_features:\n",
        "    print(f\"  {feature}: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzOYnGk5jUPs"
      },
      "source": [
        "Identifying Important Features\n",
        "\n",
        "The TF-IDF feature names are retrieved, and the logistic regression coefficients are used to determine how strongly each word influences the classification. The top positive coefficients represent words that are strong indicators of complaints, while the top negative coefficients represent words that are more commonly found in non-complaint reviews. The code prints the top 15 words for each group along with their contribution scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTJSysqlFxt0"
      },
      "source": [
        "## 8. Transformer Model Setup\n",
        "Prepare functions for training transformer models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4QzM-8jLFxt0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from transformers import TrainingArguments\n",
        "import optuna\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='macro'\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "def prepare_dataset_for_transformer(df, tokenizer, max_length=256):\n",
        "    \"\"\"Prepare dataset for transformer training\"\"\"\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=max_length\n",
        "        )\n",
        "\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "    tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "    return tokenized_dataset\n",
        "\n",
        "def get_hyperparameter_space():\n",
        "    \"\"\"Define hyperparameter search space for Optuna\"\"\"\n",
        "    return {\n",
        "        'learning_rate': (1e-5, 1e-3),\n",
        "        'per_device_train_batch_size': [8, 12],\n",
        "        'num_train_epochs': [2, 3],\n",
        "        'weight_decay': (0.01, 0.1),\n",
        "        'warmup_steps': [50, 100, 200],\n",
        "        'max_length': [128, 256]\n",
        "    }\n",
        "\n",
        "def create_training_args(trial, output_dir):\n",
        "    \"\"\"Create training arguments based on hyperparameters\"\"\"\n",
        "    return TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=trial.suggest_int('num_train_epochs', 2, 3),\n",
        "        per_device_train_batch_size=trial.suggest_categorical('batch_size', [8, 12, 16, 24]),\n",
        "        per_device_eval_batch_size=12,\n",
        "        learning_rate=trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
        "        warmup_steps=trial.suggest_categorical('warmup_steps', [100, 200, 300, 500]),\n",
        "        weight_decay=trial.suggest_uniform('weight_decay', 0.01, 0.1),\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=50,\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='f1',\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to='none',\n",
        "        seed=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "def objective(trial, model_name, train_dataset, val_dataset, tokenizer):\n",
        "    \"\"\"Optuna objective function for hyperparameter optimization\"\"\"\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2\n",
        "    ).to(device)\n",
        "\n",
        "    training_args = create_training_args(trial, f\"./results/trial_{trial.number}\")\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    return eval_results['eval_f1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "geAYEZ9Fh4Vl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjOTC5y8jqOm"
      },
      "source": [
        "Defines two functions used when training the transformer model. The `compute_metrics` function calculates evaluation metrics, including accuracy, precision, recall, and F1 score, based on model predictions and true labels. The `prepare_dataset_for_transformer` function converts the text data into a format suitable for transformer models by tokenizing the text, setting a maximum sequence length, and renaming the label column to match the expected input format. The processed dataset is then formatted into tensors so it can be used directly for model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAkd3UxmFxt0"
      },
      "source": [
        "## 9. Train RoBERTa-TL (Filipino) Model\n",
        "Fine-tune Filipino-specific transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e4f445513591477cb6b2802b096a9104",
            "14b2cfd1b6814088aa9eb504c23f287d",
            "d1fee3e433a64c17ba06cf72a4948c7e",
            "7e6dcb35c20c4a7cbb6915af46855add",
            "c1f925cefead47079aa4d6538af89332",
            "bbef1d14053046ad8220497a0b9953a8",
            "4b700a1660bf4aa4b5d424792563fbe6",
            "8db459c423a84b28a73254d1c1efd1c8",
            "1169e5cd9a59432eb7fa42591c6afc60",
            "3e22064cc9164ba0ac59ef2dbae39c35",
            "4d1d28e4e72f402eab296a5917274ac7",
            "a6f526846d834dbc9d700e106ca20849",
            "c949c408fc9d491298693d16912211a4",
            "51bad61f862d429fb02f5e22a18c5606",
            "1b696e7159444c6a962c0efd631fe28c",
            "e0c01356fb094acdaaf4e1bcb3a2872d",
            "2a36df7721cd42e1bbd143178233b299",
            "38b1df07091447c9915799b6473a4697",
            "7c48f0042ee84c69aaf927622fa45044",
            "ab8e5b18991e4c2a91532059580dcbd0",
            "c39c8289da8344bc895c0f1827fc5f5e",
            "6a8503f490ec4c6e9327876bdd713db1"
          ]
        },
        "id": "Qp9-j61yFxt0",
        "outputId": "bf7c9997-e4eb-4f00-fe30-620e5bfa2400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RoBERTa-TL (Filipino) Model with Hyperparameter Optimization\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7360 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4f445513591477cb6b2802b096a9104"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1573 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6f526846d834dbc9d700e106ca20849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:06:23,857] A new study created in memory with name: roberta_tl_optimization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting hyperparameter optimization with 5 trials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at jcblaise/roberta-tagalog-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1840' max='1840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1840/1840 06:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.310800</td>\n",
              "      <td>0.286555</td>\n",
              "      <td>0.901462</td>\n",
              "      <td>0.905223</td>\n",
              "      <td>0.877160</td>\n",
              "      <td>0.888518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.196300</td>\n",
              "      <td>0.374682</td>\n",
              "      <td>0.907184</td>\n",
              "      <td>0.908337</td>\n",
              "      <td>0.886497</td>\n",
              "      <td>0.895747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [132/132 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:13:00,676] Trial 0 finished with value: 0.895746855945468 and parameters: {'num_train_epochs': 2, 'batch_size': 8, 'learning_rate': 2.0511104188433963e-05, 'warmup_steps': 200, 'weight_decay': 0.011852604486622221}. Best is trial 0 with value: 0.895746855945468.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at jcblaise/roberta-tagalog-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2760' max='2760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2760/2760 09:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.306700</td>\n",
              "      <td>0.326692</td>\n",
              "      <td>0.888748</td>\n",
              "      <td>0.883494</td>\n",
              "      <td>0.870205</td>\n",
              "      <td>0.876132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.231500</td>\n",
              "      <td>0.388644</td>\n",
              "      <td>0.906548</td>\n",
              "      <td>0.912248</td>\n",
              "      <td>0.881909</td>\n",
              "      <td>0.894063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.073800</td>\n",
              "      <td>0.438038</td>\n",
              "      <td>0.908455</td>\n",
              "      <td>0.908480</td>\n",
              "      <td>0.889118</td>\n",
              "      <td>0.897464</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [132/132 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:22:24,036] Trial 1 finished with value: 0.8974643113225995 and parameters: {'num_train_epochs': 3, 'batch_size': 8, 'learning_rate': 4.059611610484306e-05, 'warmup_steps': 500, 'weight_decay': 0.022554447458683766}. Best is trial 1 with value: 0.8974643113225995.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at jcblaise/roberta-tagalog-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [920/920 04:58, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.269200</td>\n",
              "      <td>0.277704</td>\n",
              "      <td>0.890019</td>\n",
              "      <td>0.885278</td>\n",
              "      <td>0.871187</td>\n",
              "      <td>0.877437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.178200</td>\n",
              "      <td>0.281618</td>\n",
              "      <td>0.904005</td>\n",
              "      <td>0.905793</td>\n",
              "      <td>0.881993</td>\n",
              "      <td>0.891920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [132/132 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:27:29,511] Trial 2 finished with value: 0.8919196979686966 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 0.00010677482709481354, 'warmup_steps': 300, 'weight_decay': 0.015854643368675158}. Best is trial 1 with value: 0.8974643113225995.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at jcblaise/roberta-tagalog-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2760' max='2760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2760/2760 09:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.520500</td>\n",
              "      <td>0.505941</td>\n",
              "      <td>0.756516</td>\n",
              "      <td>0.748986</td>\n",
              "      <td>0.771731</td>\n",
              "      <td>0.748782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.553219</td>\n",
              "      <td>0.647171</td>\n",
              "      <td>0.323586</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.392898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.546200</td>\n",
              "      <td>0.544786</td>\n",
              "      <td>0.691672</td>\n",
              "      <td>0.716895</td>\n",
              "      <td>0.732696</td>\n",
              "      <td>0.689867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [132/132 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:37:11,008] Trial 3 finished with value: 0.7487820835451283 and parameters: {'num_train_epochs': 3, 'batch_size': 8, 'learning_rate': 0.000233596350262616, 'warmup_steps': 300, 'weight_decay': 0.09183883618709039}. Best is trial 1 with value: 0.8974643113225995.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at jcblaise/roberta-tagalog-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1840' max='1840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1840/1840 05:53, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.289200</td>\n",
              "      <td>0.294961</td>\n",
              "      <td>0.896376</td>\n",
              "      <td>0.903948</td>\n",
              "      <td>0.867904</td>\n",
              "      <td>0.881703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.193800</td>\n",
              "      <td>0.385461</td>\n",
              "      <td>0.904641</td>\n",
              "      <td>0.908211</td>\n",
              "      <td>0.881255</td>\n",
              "      <td>0.892272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [132/132 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:43:11,317] Trial 4 finished with value: 0.8922720797720798 and parameters: {'num_train_epochs': 2, 'batch_size': 8, 'learning_rate': 2.3426581058204037e-05, 'warmup_steps': 100, 'weight_decay': 0.06381099809299767}. Best is trial 1 with value: 0.8974643113225995.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best trial:\n",
            "  Value:  0.8974643113225995\n",
            "  Params: \n",
            "    num_train_epochs: 3\n",
            "    batch_size: 8\n",
            "    learning_rate: 4.059611610484306e-05\n",
            "    warmup_steps: 500\n",
            "    weight_decay: 0.022554447458683766\n",
            "\n",
            "Training final model with best hyperparameters...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1677283476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining final model with best hyperparameters...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m best_training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./results/roberta-tl-final\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     **{k: v for k, v in trial.params.items() if k in [\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
          ]
        }
      ],
      "source": [
        "print(\"Training RoBERTa-TL (Filipino) Model with Hyperparameter Optimization\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Install required packages for hyperparameter optimization\n",
        "!pip install -q optuna\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name_tl = \"jcblaise/roberta-tagalog-base\"\n",
        "tl_tokenizer = AutoTokenizer.from_pretrained(model_name_tl)\n",
        "\n",
        "# Add padding token if needed\n",
        "if tl_tokenizer.pad_token is None:\n",
        "    tl_tokenizer.pad_token = tl_tokenizer.eos_token\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset_tl = prepare_dataset_for_transformer(train_df, tl_tokenizer)\n",
        "val_dataset_tl = prepare_dataset_for_transformer(val_df, tl_tokenizer)\n",
        "\n",
        "# Create Optuna study for hyperparameter optimization\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    study_name=\"roberta_tl_optimization\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "n_trials = 5  # Adjust based on your computational resources\n",
        "print(f\"\\nStarting hyperparameter optimization with {n_trials} trials...\")\n",
        "\n",
        "study.optimize(\n",
        "    lambda trial: objective(\n",
        "        trial,\n",
        "        model_name_tl,\n",
        "        train_dataset_tl,\n",
        "        val_dataset_tl,\n",
        "        tl_tokenizer\n",
        "    ),\n",
        "    n_trials=n_trials\n",
        ")\n",
        "\n",
        "# Print optimization results\n",
        "print(\"\\nBest trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Train final model with best hyperparameters\n",
        "print(\"\\nTraining final model with best hyperparameters...\")\n",
        "\n",
        "best_training_args = TrainingArguments(\n",
        "    output_dir=\"./results/roberta-tl-final\",\n",
        "    **{k: v for k, v in trial.params.items() if k in [\n",
        "        'num_train_epochs', 'per_device_train_batch_size',\n",
        "        'learning_rate', 'warmup_steps', 'weight_decay'\n",
        "    ]},\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "final_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name_tl,\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "final_trainer = Trainer(\n",
        "    model=final_model,\n",
        "    args=best_training_args,\n",
        "    train_dataset=train_dataset_tl,\n",
        "    eval_dataset=val_dataset_tl,\n",
        "    tokenizer=tl_tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "# Train final model\n",
        "final_trainer.train()\n",
        "\n",
        "# Evaluate final model\n",
        "final_results = final_trainer.evaluate()\n",
        "print(\"\\nFinal Model Results:\")\n",
        "for key, value in final_results.items():\n",
        "    if not key.startswith('eval_'):\n",
        "        continue\n",
        "    metric_name = key.replace('eval_', '')\n",
        "    print(f\"  {metric_name}: {value:.4f}\")\n",
        "\n",
        "# Plot optimization history\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot([t.number for t in study.trials], [t.value for t in study.trials], 'bo-')\n",
        "plt.xlabel('Trial Number')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Hyperparameter Optimization History')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Save optimization results\n",
        "import json\n",
        "with open('hyperparameter_optimization_results.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'best_params': trial.params,\n",
        "        'best_value': trial.value,\n",
        "        'optimization_history': [\n",
        "            {'trial': t.number, 'value': t.value, 'params': t.params}\n",
        "            for t in study.trials\n",
        "        ]\n",
        "    }, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bWDyY4RlPGO"
      },
      "source": [
        "The Filipino RoBERTa model (RoBERTa-TL) was loaded along with its tokenizer and configured for binary text classification. A padding token was added if needed to ensure consistent input formatting. The training and validation datasets were tokenized and prepared using the same preprocessing method as the previous model. The model was trained using the same training parameters, including early stopping to prevent overfitting. After training, the model’s performance was evaluated on the validation dataset, and key metrics such as accuracy, precision, recall, and F1-score were generated to assess its classification effectiveness."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4f445513591477cb6b2802b096a9104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14b2cfd1b6814088aa9eb504c23f287d",
              "IPY_MODEL_d1fee3e433a64c17ba06cf72a4948c7e",
              "IPY_MODEL_7e6dcb35c20c4a7cbb6915af46855add"
            ],
            "layout": "IPY_MODEL_c1f925cefead47079aa4d6538af89332"
          }
        },
        "14b2cfd1b6814088aa9eb504c23f287d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbef1d14053046ad8220497a0b9953a8",
            "placeholder": "​",
            "style": "IPY_MODEL_4b700a1660bf4aa4b5d424792563fbe6",
            "value": "Map: 100%"
          }
        },
        "d1fee3e433a64c17ba06cf72a4948c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8db459c423a84b28a73254d1c1efd1c8",
            "max": 7360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1169e5cd9a59432eb7fa42591c6afc60",
            "value": 7360
          }
        },
        "7e6dcb35c20c4a7cbb6915af46855add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e22064cc9164ba0ac59ef2dbae39c35",
            "placeholder": "​",
            "style": "IPY_MODEL_4d1d28e4e72f402eab296a5917274ac7",
            "value": " 7360/7360 [00:02&lt;00:00, 2646.14 examples/s]"
          }
        },
        "c1f925cefead47079aa4d6538af89332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbef1d14053046ad8220497a0b9953a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b700a1660bf4aa4b5d424792563fbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8db459c423a84b28a73254d1c1efd1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1169e5cd9a59432eb7fa42591c6afc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e22064cc9164ba0ac59ef2dbae39c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1d28e4e72f402eab296a5917274ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f526846d834dbc9d700e106ca20849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c949c408fc9d491298693d16912211a4",
              "IPY_MODEL_51bad61f862d429fb02f5e22a18c5606",
              "IPY_MODEL_1b696e7159444c6a962c0efd631fe28c"
            ],
            "layout": "IPY_MODEL_e0c01356fb094acdaaf4e1bcb3a2872d"
          }
        },
        "c949c408fc9d491298693d16912211a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a36df7721cd42e1bbd143178233b299",
            "placeholder": "​",
            "style": "IPY_MODEL_38b1df07091447c9915799b6473a4697",
            "value": "Map: 100%"
          }
        },
        "51bad61f862d429fb02f5e22a18c5606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c48f0042ee84c69aaf927622fa45044",
            "max": 1573,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab8e5b18991e4c2a91532059580dcbd0",
            "value": 1573
          }
        },
        "1b696e7159444c6a962c0efd631fe28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c39c8289da8344bc895c0f1827fc5f5e",
            "placeholder": "​",
            "style": "IPY_MODEL_6a8503f490ec4c6e9327876bdd713db1",
            "value": " 1573/1573 [00:00&lt;00:00, 2285.45 examples/s]"
          }
        },
        "e0c01356fb094acdaaf4e1bcb3a2872d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a36df7721cd42e1bbd143178233b299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b1df07091447c9915799b6473a4697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c48f0042ee84c69aaf927622fa45044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8e5b18991e4c2a91532059580dcbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c39c8289da8344bc895c0f1827fc5f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a8503f490ec4c6e9327876bdd713db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}